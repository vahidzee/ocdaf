{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n",
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n",
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n",
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from ocd.models.oslow import OSlowTest\n",
    "from ocd.data.synthetic.graph_generator import GraphGenerator\n",
    "from ocd.data.synthetic.utils import RandomGenerator\n",
    "from ocd.data.synthetic.parametric import AffineParametericDataset\n",
    "from ocd.data.synthetic.nonparametric import AffineNonParametericDataset\n",
    "from ocd.models.normalization import ActNorm\n",
    "from ocd.training.trainer import Trainer\n",
    "from ocd.config import GumbelTopKConfig, BirkhoffConfig, GumbelSinkhornStraightThroughConfig, ContrastiveDivergenceConfig\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(device)\n",
    "\n",
    "num_samples = 128\n",
    "permutation_batch_size = 128\n",
    "flow_batch_size = 128\n",
    "epochs = 20000\n",
    "flow_lr = 0.005\n",
    "perm_lr = 0.005\n",
    "flow_freq = 1\n",
    "perm_freq = 4\n",
    "num_nodes = 10\n",
    "\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_nodes,\n",
    "    seed=12,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=[i for i in range(num_nodes)],\n",
    ")\n",
    "graph = graph_generator.generate_dag()\n",
    "\n",
    "# These generators are also needed to generate the data\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=30, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=1100, low=1, high=1)\n",
    "\n",
    "# parameteric with sin(x) + x non-linearity and softplus\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph=graph,\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    ")\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"Dataset wrapping tensors.\n",
    "\n",
    "    Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n",
    "    Args:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "\n",
    "dataset = CustomTensorDataset(torch.tensor(dset_sinusoidal.samples.values).float())\n",
    "flow_dataloader = DataLoader(dataset, batch_size=flow_batch_size, shuffle=True)\n",
    "permutation_dataloader = DataLoader(dataset, batch_size=permutation_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "model = OSlowTest(\n",
    "    in_features=num_nodes,\n",
    "    base_matrix=torch.eye(num_nodes),\n",
    ")\n",
    "\n",
    "\n",
    "def flow_optimizer(params): return torch.optim.Adam(params, lr=flow_lr)\n",
    "def perm_optimizer(params): return torch.optim.Adam(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "# permutation_learning_config = GumbelTopKConfig(num_samples=num_samples)\n",
    "# permutation_learning_config = ContrastiveDivergenceConfig(num_samples=num_samples)\n",
    "permutation_learning_config = GumbelSinkhornStraightThroughConfig(\n",
    "    temp=0.1, iters=20)\n",
    "# permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "for temperature_scheduler in ['linear', 'constant']:\n",
    "    temperature = 1.\n",
    "\n",
    "    birkhoff_config = None if num_nodes > 4 else BirkhoffConfig(\n",
    "        num_samples=100, frequency=1, print_legend=False)\n",
    "    trainer = Trainer(model=model,\n",
    "                      dag=graph,\n",
    "                      flow_dataloader=flow_dataloader,\n",
    "                      perm_dataloader=permutation_dataloader,\n",
    "                      flow_optimizer=flow_optimizer,\n",
    "                      permutation_optimizer=perm_optimizer,\n",
    "                      flow_frequency=flow_freq,\n",
    "                      temperature=temperature,\n",
    "                      temperature_scheduler=temperature_scheduler,\n",
    "                      permutation_frequency=perm_freq,\n",
    "                      max_epochs=epochs,\n",
    "                      flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                      permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                      permutation_learning_config=permutation_learning_config,\n",
    "                      birkhoff_config=birkhoff_config,\n",
    "                      device=device)\n",
    "    wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "               tags=[\n",
    "                   permutation_learning_config.method,\n",
    "                   f\"num_nodes-{num_nodes}\",\n",
    "                   f\"epochs-{epochs}\",\n",
    "                   f\"base-temperature-{temperature}\",\n",
    "                   f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "                   \"no-sigmoid\",\n",
    "               ],)\n",
    "    trainer.train()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
